{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cda5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a39e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"9E1U5DFIkPOiR1xAAP9rhw2GA\"\n",
    "consumer_secret = \"wMNX3b3oSw672AoYVBdIxQUwPOiRnUX60slKPK9eBQ2C3X1h8o\"\n",
    "access_token = \"1546125629783166976-2kWTcEqJhqTIqwUm32rsMDMMLMxlmC\"\n",
    "access_token_secret = \"HIKijMFakNNA1aWuo3ROELvGkFrMo26tiqkF75THl1Z0f\"\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "  consumer_key, \n",
    "  consumer_secret, \n",
    "  access_token, \n",
    "  access_token_secret\n",
    ")\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a299acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashmap = {\n",
    "    \"Hyderabad\": \"17.3850,78.4867\",\n",
    "    \"Mumbai\": \"19.0760,72.8777\",\n",
    "    \"Chennai\": \"13.0827,80.2707\",\n",
    "    \"Delhi\":  \"28.7041,77.1025\",\n",
    "    \"London\": \"51.5072 ,0.1276\",\n",
    "    \"Paris\":\"48.8566, 2.3522\",\n",
    "    \"Amsterdam\":\"52.3676,4.9041\",\n",
    "    \"Sydney\":\"33.8688, 151.2093\",\n",
    "    \"Melbourne\":\"33.8688,151.2093\",\n",
    "    \"Perth\":\"31.9523,115.8613\",\n",
    "    \"Hobart\":\"42.8826,147.3257\",\n",
    "    \"Canberra\":\"35.2802,149.1310\",\n",
    "    \"Berlin\":\"52.5200,13.4050\",\n",
    "    \"Budapest\":\"47.4979,19.0402\",\n",
    "    \"Rome\":\"41.9028,12.4964\",\n",
    "    \"Madrid\":\"40.4168,3.7038\",\n",
    "    \"Moscow\":\"55.7558,37.6173\",\n",
    "    \"Istanbul\":\"41.0082,28.9784\",\n",
    "    \"Mexico City\": \"19.4326, 99.1332\",\n",
    "    \"São Paulo\": \"-23.5505, -46.6333\",\n",
    "    \"New York City\": \"40.7128, -74.0060\",\n",
    "    \"Los Angeles\": \"34.0522, -118.2437\",\n",
    "    \"Buenos Aires\": \"-34.6037, -58.3816\",\n",
    "    \"Rio de Janeiro\": \"-22.9068,-43.1729\",\n",
    "    \"Toronto\": \"43.6532, -79.3832\",\n",
    "    \"Lima\": \"-12.0432, -77.0282\",\n",
    "    \"Chicago\": \"41.8781, -87.6298\",\n",
    "    \"Bogotá\": \"4.7109, -74.0724\",\n",
    "    \"Houston\": \"29.7604, -95.3698\",\n",
    "    \"Santiago\": \"-33.4489, -70.6693\",\n",
    "    \"Havana\": \"23.113, -82.3666\",\n",
    "    \"Ecatepec de Morees\": \"19.6011, -99.0523\",\n",
    "    \"Philadelphia\": \"39.9526, -75.1652\",\n",
    "    \"Tokyo\" : \"139.6917, 35.6895\",\n",
    "    \"Shanghai\" : \"121.4737, 31.2304\",\n",
    "    \"Manila\" : \"120.9842, 14.5995\",\n",
    "    \"Seoul\" : \"126.9780, 37.5665\",\n",
    "    \"Dhaka\" : \"90.4125, 23.8103\",\n",
    "    \"Beijing\" : \"116.4074, 39.9042\",\n",
    "    \"Bangkok\" : \"100.5018, 13.7563\",\n",
    "    \"Kolkata\" : \"88.3639, 22.5726\",\n",
    "    \"Bangalore\" : \"77.5946, 12.9716\",\n",
    "    \"Ahmedabad\" : \"72.5714, 23.0225\",\n",
    "    \"Taipei\" : \"121.5654, 25.0330\",\n",
    "    \"Kuala Lumpur\" : \"101.6869, 3.1390\",\n",
    "    \"Singapore\" : \"103.8198, 1.3521\",\n",
    "    \"Hong Kong\" : \"114.1491, 22.2855\",\n",
    "    \"Baghdad\" : \"44.3615, 33.3128\",\n",
    "    \"Tehran\" : \"51.3890, 35.6892\",\n",
    "    \"Guangzhou-Foshan\" : \"23.02677,113.13148\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3a799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing the background noises\n",
      "Ask me anything\n",
      "Done recording\n",
      "The word given is diabetes\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice',voices[1].id)\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "try:\n",
    "    with sr.Microphone() as Source:\n",
    "        print('Clearing the background noises')\n",
    "        recognizer.adjust_for_ambient_noise(Source,duration=2)\n",
    "        print(\"Ask me anything\")\n",
    "        recordaudio = recognizer.listen(Source,timeout=5)\n",
    "        print(\"Done recording\")\n",
    "    text = recognizer.recognize_google(recordaudio)\n",
    "    text = text.lower()\n",
    "    print(\"The word given is {}\".format(text))\n",
    "    engine.say(\"The word given is {}\".format(text))\n",
    "    engine.runAndWait()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"No value recorded\")\n",
    "    text = input(\"Enter the search query : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6829b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbaf7bd0e854cada5a5bd9db99140f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('Hyderabad', 'Mumbai', 'Chennai', 'Delhi', 'London', 'Paris', 'Amsterdam', 'Sydney', 'Melbou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import *\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import *\n",
    "\n",
    "city = Dropdown(options = list(hashmap.keys()))\n",
    "display(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45f44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_tweets = []\n",
    "\n",
    "for status in tweepy.Cursor(api.search_tweets, \n",
    "                            text+\"-filter:retweets\", \n",
    "                            lang=\"en\",\n",
    "                            geocode = hashmap.get(city.value)+\",100km\",\n",
    "                            tweet_mode='extended',\n",
    "                            count=50).items(5000):\n",
    "    extracted_tweets.append(status)\n",
    "\n",
    "users_locs = [[tweet.full_text] for tweet in extracted_tweets]\n",
    "twitterDf = pd.DataFrame(data=users_locs,columns=[\"Tweet\"])\n",
    "twitterDf.to_csv(\"P2_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b7aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
